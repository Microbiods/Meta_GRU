{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Windows:  [(-5.0, -0.5), (-3.5, 1.0), (-2.0, 2.5), (-0.5, 4.0), (1.0, 5.5), (2.5, 7.0), (4.0, 8.5), (5.5, 10.0)]\n",
      "Time start:  -5.0\n",
      "Time end:  10.0\n",
      "Comb:  (20, 308, 8)\n",
      "Label length:  20\n"
     ]
    }
   ],
   "source": [
    "!python3 data_generate.py -fn david"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine features (sizes * features * time points):  (20, 308, 8)\n",
      "Label size:  20\n",
      "==================== 1 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 1 AUC :  0.5000\n",
      "Fold 1 F1 :  0.5000\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.5000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.5000\n",
      "Fold 2 F1 :  0.5000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  0.7500\n",
      "Fold 3 F1 :  0.8000\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  0.6667\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.6667\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  0.5000\n",
      "\n",
      "\n",
      "1 rounds average AUC :  0.7500\n",
      "1 rounds average F1 :  0.4933\n",
      "1 rounds average ACC :  0.6000\n",
      "1 rounds average Precision :  0.5333\n",
      "1 rounds average Recall :  0.5000\n",
      "==================== 2 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 1 AUC :  0.5000\n",
      "Fold 1 F1 :  0.0000\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.0000\n",
      "Fold 1 Recall :  0.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.5000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  0.7500\n",
      "Fold 3 F1 :  0.5000\n",
      "Fold 3 ACC :  0.5000\n",
      "Fold 3 Precision :  0.5000\n",
      "Fold 3 Recall :  0.5000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "2 rounds average AUC :  0.6500\n",
      "2 rounds average F1 :  0.4000\n",
      "2 rounds average ACC :  0.6000\n",
      "2 rounds average Precision :  0.4000\n",
      "2 rounds average Recall :  0.4000\n",
      "==================== 3 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 1 AUC :  0.5000\n",
      "Fold 1 F1 :  0.0000\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.0000\n",
      "Fold 1 Recall :  0.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.4000\n",
      "Fold 2 ACC :  0.2500\n",
      "Fold 2 Precision :  0.3333\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  0.5000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.8000\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  0.6667\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "3 rounds average AUC :  0.7000\n",
      "3 rounds average F1 :  0.3733\n",
      "3 rounds average ACC :  0.5500\n",
      "3 rounds average Precision :  0.4000\n",
      "3 rounds average Recall :  0.4000\n",
      "==================== 4 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.6667\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  0.7500\n",
      "Fold 3 F1 :  0.6667\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  0.5000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "Fold 4 ACC :  1.0000\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.0000\n",
      "Fold 5 ACC :  0.5000\n",
      "Fold 5 Precision :  0.0000\n",
      "Fold 5 Recall :  0.0000\n",
      "\n",
      "\n",
      "4 rounds average AUC :  0.8000\n",
      "4 rounds average F1 :  0.6000\n",
      "4 rounds average ACC :  0.7000\n",
      "4 rounds average Precision :  0.7000\n",
      "4 rounds average Recall :  0.6000\n",
      "==================== 5 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.5000\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.4000\n",
      "Fold 2 ACC :  0.2500\n",
      "Fold 2 Precision :  0.3333\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "Fold 3 ACC :  0.5000\n",
      "Fold 3 Precision :  0.5000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.8000\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  0.6667\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "5 rounds average AUC :  0.8500\n",
      "5 rounds average F1 :  0.5067\n",
      "5 rounds average ACC :  0.5000\n",
      "5 rounds average Precision :  0.4000\n",
      "5 rounds average Recall :  0.7000\n",
      "==================== 6 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 1 AUC :  0.7500\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.5000\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.5000\n",
      "Fold 2 F1 :  0.5000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.8000\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  0.6667\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.8000\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  0.6667\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "6 rounds average AUC :  0.8500\n",
      "6 rounds average F1 :  0.5533\n",
      "6 rounds average ACC :  0.6000\n",
      "6 rounds average Precision :  0.4667\n",
      "6 rounds average Recall :  0.7000\n",
      "==================== 7 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 1 AUC :  0.5000\n",
      "Fold 1 F1 :  0.0000\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.0000\n",
      "Fold 1 Recall :  0.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.6667\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  0.5000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "Fold 4 ACC :  0.7500\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  0.5000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "7 rounds average AUC :  0.7500\n",
      "7 rounds average F1 :  0.6000\n",
      "7 rounds average ACC :  0.7000\n",
      "7 rounds average Precision :  0.7000\n",
      "7 rounds average Recall :  0.6000\n",
      "==================== 8 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.8000\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  0.6667\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.5000\n",
      "Fold 2 F1 :  0.6667\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "Fold 3 ACC :  0.5000\n",
      "Fold 3 Precision :  0.5000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "8 rounds average AUC :  0.8500\n",
      "8 rounds average F1 :  0.6267\n",
      "8 rounds average ACC :  0.6500\n",
      "8 rounds average Precision :  0.5333\n",
      "8 rounds average Recall :  0.8000\n",
      "==================== 9 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 1 AUC :  0.7500\n",
      "Fold 1 F1 :  0.8000\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  0.6667\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.5000\n",
      "Fold 2 F1 :  0.6667\n",
      "Fold 2 ACC :  0.7500\n",
      "Fold 2 Precision :  1.0000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.8000\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  0.6667\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.8000\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  0.6667\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "9 rounds average AUC :  0.8000\n",
      "9 rounds average F1 :  0.6133\n",
      "9 rounds average ACC :  0.7000\n",
      "9 rounds average Precision :  0.6000\n",
      "9 rounds average Recall :  0.7000\n",
      "==================== 10 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 1 AUC :  0.5000\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.6667\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimension to mlp:  (16, 2464) (4, 2464)\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.8000\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  0.6667\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "10 rounds average AUC :  0.7000\n",
      "10 rounds average F1 :  0.6267\n",
      "10 rounds average ACC :  0.7000\n",
      "10 rounds average Precision :  0.6333\n",
      "10 rounds average Recall :  0.7000\n",
      "\n",
      "\n",
      "#################### Over! ####################\n",
      "10 rounds average 5-fold  AUC :  0.7700\n",
      "10 rounds average 5-fold  F1 :  0.5393\n",
      "10 rounds average 5-fold  ACC :  0.6300\n",
      "10 rounds average 5-fold  Precision :  0.5367\n",
      "10 rounds average 5-fold  Recall :  0.6100\n",
      "\n",
      "\n",
      "Best seed for 10 rounds:  4\n",
      "Best AUC for 10 rounds: 0.8500\n",
      "Best F1 for 10 rounds: 0.5067\n",
      "True_label: \t\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "Best_pro: \t\n",
      "[0.9733239166501078, 0.9676109932605297, 0.9999999528062311, 0.9983461895442611, 0.9999526363145061, 0.8860624638574305, 0.997339084036657, 9.294643080310385e-06, 0.9998385485648269, 0.9999999960087202, 0.9999999999998328, 0.9999999999996438, 0.0004454243830280403, 6.309625700349158e-13, 0.21715578799216947, 0.002238529298708009, 0.5608075590525723, 6.902842399110612e-07, 0.9999366368735354, 0.9999936154804726]\n"
     ]
    }
   ],
   "source": [
    "!python3 com_dl.py -fn david -clf mlp -rs 10 -es tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine features (sizes * features * time points):  (20, 308, 8)\n",
      "Label size:  20\n",
      "==================== 1 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 34ms/step - loss: 0.7626 - accuracy: 0.4500\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7871 - accuracy: 0.5000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6896 - accuracy: 0.5417\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6344 - accuracy: 0.6667 0s - loss: 0.6130 - accuracy: 0.73\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7531 - accuracy: 0.5917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7037 - accuracy: 0.5417\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6310 - accuracy: 0.5417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5615 - accuracy: 0.8333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5372 - accuracy: 0.7750\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5614 - accuracy: 0.8583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6284 - accuracy: 0.7667\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5136 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4768 - accuracy: 0.9583\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4519 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4600 - accuracy: 0.9583\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4639 - accuracy: 0.9750\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4004 - accuracy: 0.8833\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4703 - accuracy: 0.9750\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3342 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4182 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4189 - accuracy: 0.9167\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3454 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3486 - accuracy: 0.9333\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2470 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3396 - accuracy: 1.0000 0s - loss: 0.3605 - accuracy: 1.00\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3396 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3139 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3221 - accuracy: 0.9583\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2564 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2880 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3521 - accuracy: 0.8833\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2308 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2661 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2329 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2347 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2211 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2383 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2354 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2715 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2057 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2335 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2896 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2537 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2092 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1713 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2547 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2910 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3100 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2451 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2462 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2591 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 1.00 - 0s 40ms/step - loss: 0.2051 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2242 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1942 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2705 - accuracy: 1.0000\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8295 - accuracy: 0.20 - 3s 35ms/step - loss: 0.8180 - accuracy: 0.2500\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7862 - accuracy: 0.2750\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7495 - accuracy: 0.4333\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7888 - accuracy: 0.4250\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6921 - accuracy: 0.4583\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6199 - accuracy: 0.8167 0s - loss: 0.5996 - accuracy: 0.90\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6186 - accuracy: 0.8000\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5766 - accuracy: 0.7083\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5718 - accuracy: 0.8417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5658 - accuracy: 0.8667\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4899 - accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5627 - accuracy: 0.7750\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4819 - accuracy: 0.9750\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4839 - accuracy: 0.9583\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5053 - accuracy: 0.8417\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4710 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4694 - accuracy: 0.8833\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4023 - accuracy: 0.8833\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3692 - accuracy: 1.0000 0s - loss: 0.3424 - accuracy: 1.00\n",
      "Epoch 20/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4300 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5015 - accuracy: 0.8833\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4164 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4578 - accuracy: 0.9333\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3391 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3360 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3720 - accuracy: 0.9333\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4363 - accuracy: 0.9333\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2956 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2852 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2588 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3993 - accuracy: 0.9333\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 1.00 - 0s 40ms/step - loss: 0.3334 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2879 - accuracy: 0.9750\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4116 - accuracy: 0.8833\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3512 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3249 - accuracy: 1.0000 0s - loss: 0.3313 - accuracy: 1.00\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3176 - accuracy: 0.8833\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3068 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3094 - accuracy: 0.9583\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3701 - accuracy: 0.8833\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "Fold 2 ACC :  1.0000\n",
      "Fold 2 Precision :  1.0000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 33ms/step - loss: 0.7174 - accuracy: 0.4083\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6500 - accuracy: 0.6917\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6850 - accuracy: 0.5000\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6710 - accuracy: 0.5417\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6829 - accuracy: 0.5083\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6102 - accuracy: 0.6583\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6243 - accuracy: 0.8500\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5594 - accuracy: 0.8667\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5698 - accuracy: 0.7333\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6226 - accuracy: 0.8833\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6188 - accuracy: 0.7250\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6202 - accuracy: 0.5500\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5927 - accuracy: 0.7500\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4770 - accuracy: 0.9583\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4812 - accuracy: 0.9583\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5410 - accuracy: 0.8417\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5295 - accuracy: 0.9583\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5818 - accuracy: 0.7417\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4376 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5429 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5611 - accuracy: 0.8167\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5017 - accuracy: 0.8667\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5418 - accuracy: 0.8167\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4782 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5276 - accuracy: 0.7917\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4845 - accuracy: 0.9333\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5426 - accuracy: 0.8417\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4907 - accuracy: 0.9750\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4956 - accuracy: 0.8667\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 33ms/step - loss: 0.6426 - accuracy: 0.7083\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7198 - accuracy: 0.5500\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6790 - accuracy: 0.6583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6848 - accuracy: 0.5750\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6489 - accuracy: 0.6333\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6807 - accuracy: 0.5000\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5880 - accuracy: 0.7667\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6337 - accuracy: 0.8917\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5715 - accuracy: 0.7250\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5532 - accuracy: 0.7917\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5058 - accuracy: 0.9583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5210 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5036 - accuracy: 0.8833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4577 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4330 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4127 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 1.00 - 0s 34ms/step - loss: 0.3509 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3204 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3320 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3785 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3413 - accuracy: 0.8833\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3278 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2990 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 1.00 - 0s 37ms/step - loss: 0.2520 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2847 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2369 - accuracy: 1.0000\n",
      "Epoch 27/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2405 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2441 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1956 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1960 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1589 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1739 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2038 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1384 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1274 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1899 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1298 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1498 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1256 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1294 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 1.00 - 0s 37ms/step - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1014 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0890 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1342 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0884 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 1.00 - 0s 39ms/step - loss: 0.0755 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0822 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0727 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0979 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0846 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0946 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0944 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0827 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1206 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0601 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0539 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0741 - accuracy: 1.0000 0s - loss: 0.0729 - accuracy: 1.00\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 1.00 - 0s 34ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0938 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0735 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 1.00 - 0s 36ms/step - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0709 - accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 1.00 - 0s 38ms/step - loss: 0.0821 - accuracy: 1.0000\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0564 - accuracy: 1.0000 0s - loss: 0.0520 - accuracy: 1.00\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "Fold 4 ACC :  0.7500\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  0.5000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 32ms/step - loss: 0.6612 - accuracy: 0.5250\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6377 - accuracy: 0.6417\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7013 - accuracy: 0.7000\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6458 - accuracy: 0.8667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6676 - accuracy: 0.8000\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6521 - accuracy: 0.6833\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5769 - accuracy: 0.6667\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5865 - accuracy: 0.8417\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6595 - accuracy: 0.6250\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7055 - accuracy: 0.5667\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5701 - accuracy: 0.8583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5748 - accuracy: 0.7250\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5163 - accuracy: 0.9083\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4082 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4742 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4643 - accuracy: 0.9500\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5644 - accuracy: 0.9583\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4794 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5066 - accuracy: 0.8833\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5080 - accuracy: 0.8167\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4657 - accuracy: 0.9583\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4307 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4453 - accuracy: 0.8667\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4352 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86513c0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUC :  0.7500\n",
      "Fold 5 F1 :  0.6667\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  0.5000\n",
      "\n",
      "\n",
      "1 rounds average AUC :  0.9500\n",
      "1 rounds average F1 :  0.8000\n",
      "1 rounds average ACC :  0.8500\n",
      "1 rounds average Precision :  1.0000\n",
      "1 rounds average Recall :  0.7000\n",
      "==================== 2 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 36ms/step - loss: 0.6861 - accuracy: 0.6083\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7579 - accuracy: 0.5167\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7390 - accuracy: 0.3167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6238 - accuracy: 0.6333\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6842 - accuracy: 0.6000\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6633 - accuracy: 0.6333\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6021 - accuracy: 0.7250\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.6939 - accuracy: 0.4667\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5960 - accuracy: 0.8667\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6532 - accuracy: 0.6833\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5993 - accuracy: 0.7500\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4762 - accuracy: 0.9583\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5632 - accuracy: 0.9500\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5397 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5743 - accuracy: 0.7000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5945 - accuracy: 0.8000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5184 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5712 - accuracy: 0.7667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5504 - accuracy: 0.8833\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5569 - accuracy: 0.7250\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5004 - accuracy: 0.9583\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5299 - accuracy: 0.9583\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651938b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  0.0000\n",
      "Fold 1 F1 :  0.0000\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.0000\n",
      "Fold 1 Recall :  0.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 32ms/step - loss: 0.7177 - accuracy: 0.3917\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7382 - accuracy: 0.5333\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7533 - accuracy: 0.3833\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7772 - accuracy: 0.3667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7094 - accuracy: 0.5250\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6122 - accuracy: 0.8000\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6126 - accuracy: 0.8333\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5923 - accuracy: 0.9583\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7202 - accuracy: 0.6417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6819 - accuracy: 0.6500\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6280 - accuracy: 0.8167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6044 - accuracy: 0.8167\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5569 - accuracy: 0.7750\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6382 - accuracy: 0.7750\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5739 - accuracy: 0.9333\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5966 - accuracy: 0.9333\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5932 - accuracy: 0.8417\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6615 - accuracy: 0.6917\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5221 - accuracy: 0.8667\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5241 - accuracy: 0.8667\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5397 - accuracy: 0.8000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5233 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5380 - accuracy: 0.8417\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4775 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.90 - 0s 41ms/step - loss: 0.5259 - accuracy: 0.8917\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4948 - accuracy: 0.8333\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5745 - accuracy: 0.7500\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5323 - accuracy: 0.8833\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 1.00 - 0s 42ms/step - loss: 0.5445 - accuracy: 0.9750\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5980 - accuracy: 0.7917\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4613 - accuracy: 0.9750\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5428 - accuracy: 0.8500\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5895 - accuracy: 0.7917\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4896 - accuracy: 0.8667\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f866ae21d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.5000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 34ms/step - loss: 0.6933 - accuracy: 0.4750\n",
      "Epoch 2/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6836 - accuracy: 0.4750\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7122 - accuracy: 0.4250\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7025 - accuracy: 0.6167\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6148 - accuracy: 0.7500\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6548 - accuracy: 0.6333\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5867 - accuracy: 0.7250\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5827 - accuracy: 0.7500\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5495 - accuracy: 0.8667\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5376 - accuracy: 0.7917\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6541 - accuracy: 0.5250\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5554 - accuracy: 0.6583\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5645 - accuracy: 0.7667\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4916 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4855 - accuracy: 0.9583\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4363 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4665 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3331 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3661 - accuracy: 0.9583\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3652 - accuracy: 0.8833\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4035 - accuracy: 0.9333\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3638 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3975 - accuracy: 0.9333\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3657 - accuracy: 0.8833\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4524 - accuracy: 0.8833\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2544 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3361 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2945 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2581 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3354 - accuracy: 0.8833\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3610 - accuracy: 0.8833\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3807 - accuracy: 0.9333\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3013 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2879 - accuracy: 0.9750\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3399 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3540 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2658 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2632 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2822 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8677eb9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.8000\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  0.6667\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 32ms/step - loss: 0.8027 - accuracy: 0.3167\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7310 - accuracy: 0.5250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6332 - accuracy: 0.7500\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6086 - accuracy: 0.7917\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6192 - accuracy: 0.6583\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.6837 - accuracy: 0.7333\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5245 - accuracy: 0.9333\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5286 - accuracy: 0.8833\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5817 - accuracy: 0.8417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5375 - accuracy: 0.9583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4966 - accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4974 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4603 - accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5282 - accuracy: 0.8833\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4797 - accuracy: 0.9083\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4832 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4182 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4265 - accuracy: 0.8833\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3825 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3358 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3525 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3906 - accuracy: 1.0000 0s - loss: 0.4053 - accuracy: 1.00\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2974 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3822 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2717 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2233 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2383 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2390 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2178 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2062 - accuracy: 0.9583\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2504 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2321 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1587 - accuracy: 1.0000\n",
      "Epoch 35/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1850 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1424 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1382 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1618 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1436 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1534 - accuracy: 1.0000 0s - loss: 0.1653 - accuracy: 1.00\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1227 - accuracy: 1.0000 0s - loss: 0.1257 - accuracy: 1.00\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1646 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0847 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1146 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1715 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1341 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0948 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0796 - accuracy: 1.0000 0s - loss: 0.0767 - accuracy: 1.00\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1079 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1063 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0782 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1082 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0895 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0670 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0783 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0796 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0720 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1166 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1091 - accuracy: 1.0000 0s - loss: 0.1108 - accuracy: 1.00\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1157 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0935 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1172 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1059 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0997 - accuracy: 1.0000\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0827 - accuracy: 1.0000\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0720 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8664b15840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "Fold 4 ACC :  1.0000\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 36ms/step - loss: 0.8328 - accuracy: 0.1333\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7043 - accuracy: 0.5417\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7072 - accuracy: 0.5583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6317 - accuracy: 0.7333\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6491 - accuracy: 0.5500\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6642 - accuracy: 0.5417\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6071 - accuracy: 0.7750\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7136 - accuracy: 0.5167\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6082 - accuracy: 0.7750\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5536 - accuracy: 0.9583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5792 - accuracy: 0.8917 0s - loss: 0.5898 - accuracy: 0.90\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5661 - accuracy: 0.8583\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5183 - accuracy: 0.8833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5287 - accuracy: 0.8833\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4614 - accuracy: 0.9583\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4475 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4496 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4298 - accuracy: 0.8667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.4111 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4327 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3900 - accuracy: 0.9333\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3985 - accuracy: 0.9750\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3576 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3324 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3302 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2541 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3437 - accuracy: 0.9583\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2539 - accuracy: 1.0000 0s - loss: 0.2306 - accuracy: 1.00\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2677 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2841 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2324 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2214 - accuracy: 1.0000\n",
      "Epoch 33/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2648 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2422 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1581 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2269 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2040 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2344 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1844 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1655 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2100 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2439 - accuracy: 1.0000 0s - loss: 0.2611 - accuracy: 1.00\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1599 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1882 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86526017b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "2 rounds average AUC :  0.6500\n",
      "2 rounds average F1 :  0.6600\n",
      "2 rounds average ACC :  0.7500\n",
      "2 rounds average Precision :  0.6333\n",
      "2 rounds average Recall :  0.7000\n",
      "==================== 3 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 35ms/step - loss: 0.7109 - accuracy: 0.6167\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7463 - accuracy: 0.5250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7920 - accuracy: 0.4583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.76 - 0s 34ms/step - loss: 0.6047 - accuracy: 0.7083\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6167 - accuracy: 0.6500\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6456 - accuracy: 0.5667\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6256 - accuracy: 0.8000\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5687 - accuracy: 0.9750\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5090 - accuracy: 0.9500\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5723 - accuracy: 0.7750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4497 - accuracy: 0.9583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4781 - accuracy: 0.9583\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3945 - accuracy: 0.9750\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4556 - accuracy: 0.8833 0s - loss: 0.4602 - accuracy: 0.84\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4862 - accuracy: 0.8417\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4471 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3795 - accuracy: 0.9750\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4176 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3847 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3609 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3694 - accuracy: 0.9750\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3651 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3936 - accuracy: 1.0000 0s - loss: 0.4074 - accuracy: 1.00\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3163 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3340 - accuracy: 0.9750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3323 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3487 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3342 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2788 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2789 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2861 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2858 - accuracy: 0.9333\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2933 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3338 - accuracy: 0.9333\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3055 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3224 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2425 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.2756 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3485 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2826 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3085 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3000 - accuracy: 0.9583\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - 0s 37ms/step - loss: 0.3382 - accuracy: 0.8833\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3105 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3223 - accuracy: 0.8417\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2891 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2568 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651270268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.8000\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  0.6667\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 34ms/step - loss: 0.7288 - accuracy: 0.5250\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7095 - accuracy: 0.6083\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7106 - accuracy: 0.4083\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6145 - accuracy: 0.6417\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6777 - accuracy: 0.6333\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6048 - accuracy: 0.7667\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5212 - accuracy: 0.9750\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6289 - accuracy: 0.6083\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5634 - accuracy: 0.7917\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5626 - accuracy: 0.6750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5403 - accuracy: 0.6583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4830 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4908 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5118 - accuracy: 0.8833\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4068 - accuracy: 0.9583\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4434 - accuracy: 0.8667\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3742 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3859 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4033 - accuracy: 0.8417\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3777 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3817 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3637 - accuracy: 0.9583\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3384 - accuracy: 0.9333\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3214 - accuracy: 0.9750\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4288 - accuracy: 0.7667\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.3370 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3655 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2959 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3098 - accuracy: 0.9583\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3067 - accuracy: 0.9583\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2411 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3266 - accuracy: 0.8833\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2679 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2927 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2899 - accuracy: 0.9333\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3484 - accuracy: 1.0000 0s - loss: 0.3754 - accuracy: 1.00\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2596 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2558 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2080 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2213 - accuracy: 0.9583\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2728 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2241 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2693 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2698 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2617 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1933 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2458 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2576 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1988 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2129 - accuracy: 0.9750\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2514 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1997 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2138 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2570 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2301 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f867d8a5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  0.5000\n",
      "Fold 2 F1 :  0.4000\n",
      "Fold 2 ACC :  0.2500\n",
      "Fold 2 Precision :  0.3333\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.55 - 3s 32ms/step - loss: 0.6664 - accuracy: 0.5083\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6814 - accuracy: 0.4333\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7017 - accuracy: 0.4750\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6716 - accuracy: 0.5667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6785 - accuracy: 0.5833\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6053 - accuracy: 0.6833\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5745 - accuracy: 0.8250\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5460 - accuracy: 0.7917 0s - loss: 0.5525 - accuracy: 0.77\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5325 - accuracy: 0.8583\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5659 - accuracy: 0.8167\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5107 - accuracy: 0.9083\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5033 - accuracy: 0.9083\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4073 - accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4606 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4149 - accuracy: 0.9333\n",
      "Epoch 16/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3663 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3539 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4341 - accuracy: 0.9083\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3895 - accuracy: 0.9083\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3388 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2680 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2697 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2538 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 1.00 - 0s 34ms/step - loss: 0.2735 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2978 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3291 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2229 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3013 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2966 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2213 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2647 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2036 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2321 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1639 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1643 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2109 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 1.00 - 0s 41ms/step - loss: 0.2004 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1924 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1663 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2076 - accuracy: 1.0000 0s - loss: 0.1982 - accuracy: 1.00\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1952 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1618 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1807 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1966 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8664b3bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 32ms/step - loss: 0.7142 - accuracy: 0.3833\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7137 - accuracy: 0.5000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6506 - accuracy: 0.6167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6661 - accuracy: 0.6750\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7362 - accuracy: 0.5917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6709 - accuracy: 0.4583\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6911 - accuracy: 0.4500\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5774 - accuracy: 1.0000\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6133 - accuracy: 0.8917\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5480 - accuracy: 0.8250\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5612 - accuracy: 0.8167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5817 - accuracy: 0.8167\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5173 - accuracy: 0.8417\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5063 - accuracy: 0.8833\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4671 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4602 - accuracy: 0.9500\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4919 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4620 - accuracy: 0.8833\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4340 - accuracy: 0.9333\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4264 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3826 - accuracy: 0.9333\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3963 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 1.00 - 0s 37ms/step - loss: 0.4020 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3269 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3300 - accuracy: 0.9750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3352 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2624 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3325 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3037 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2373 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2437 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2856 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2540 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2787 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2371 - accuracy: 1.0000 0s - loss: 0.2398 - accuracy: 1.00\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.2259 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2187 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1748 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2059 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1509 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2144 - accuracy: 1.0000\n",
      "Epoch 42/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1759 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1907 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 1.00 - 0s 40ms/step - loss: 0.1598 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1544 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2226 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2051 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2364 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2109 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2162 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1969 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1505 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1657 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2138 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2131 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f865228a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "Fold 4 ACC :  0.7500\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  0.5000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 33ms/step - loss: 0.6851 - accuracy: 0.5917\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7199 - accuracy: 0.5250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6807 - accuracy: 0.6083\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6245 - accuracy: 0.7583\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6504 - accuracy: 0.7000\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6380 - accuracy: 0.7333\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6237 - accuracy: 0.8000 0s - loss: 0.6133 - accuracy: 0.87\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6001 - accuracy: 0.7750\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5639 - accuracy: 0.7917\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5139 - accuracy: 0.9750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4925 - accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6356 - accuracy: 0.6083\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4827 - accuracy: 0.7917\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4798 - accuracy: 0.8417\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4578 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4499 - accuracy: 0.8167\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4876 - accuracy: 0.8167\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5434 - accuracy: 0.7917\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3870 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4204 - accuracy: 0.9583\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3427 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3977 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3509 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3311 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3412 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2935 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1996 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2761 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2535 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2410 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2098 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2067 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2029 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2565 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2350 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2260 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1951 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1986 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1553 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1594 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1568 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1959 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1709 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1843 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1147 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1666 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1354 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1605 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1293 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1582 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1453 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1308 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1542 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1464 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1553 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1843 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1742 - accuracy: 1.0000\n",
      "Epoch 58/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1643 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1617 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1348 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1454 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1537 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651276ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  0.7500\n",
      "Fold 5 F1 :  0.6667\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  0.5000\n",
      "\n",
      "\n",
      "3 rounds average AUC :  0.8500\n",
      "3 rounds average F1 :  0.7067\n",
      "3 rounds average ACC :  0.7000\n",
      "3 rounds average Precision :  0.8000\n",
      "3 rounds average Recall :  0.7000\n",
      "==================== 4 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 41ms/step - loss: 0.6998 - accuracy: 0.5667\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6760 - accuracy: 0.6750\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6968 - accuracy: 0.6667\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6750 - accuracy: 0.5417\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6461 - accuracy: 0.7250\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6941 - accuracy: 0.5750\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6415 - accuracy: 0.6333\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5970 - accuracy: 0.6417\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5909 - accuracy: 0.8833\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5753 - accuracy: 0.8583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5150 - accuracy: 0.9500\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5015 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5149 - accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5063 - accuracy: 0.7750\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4515 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4914 - accuracy: 0.8667\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5472 - accuracy: 0.7667\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4212 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4808 - accuracy: 0.9083\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4361 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3532 - accuracy: 0.9750\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3302 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3816 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3319 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3361 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3199 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3402 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3571 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3074 - accuracy: 1.0000 0s - loss: 0.3034 - accuracy: 1.00\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2686 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2578 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3427 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2455 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2991 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1954 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2524 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3494 - accuracy: 0.9750\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2206 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2604 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2112 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1967 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2183 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2045 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2954 - accuracy: 0.9750\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2404 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2782 - accuracy: 0.9583\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2752 - accuracy: 0.9333\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3422 - accuracy: 0.8583\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1832 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2582 - accuracy: 0.8833\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2207 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2795 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2357 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2337 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1972 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3209 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2697 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2401 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2029 - accuracy: 0.9750\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f866a442e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 31ms/step - loss: 0.6652 - accuracy: 0.6167\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6548 - accuracy: 0.7750\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6250 - accuracy: 0.8500\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7116 - accuracy: 0.5417\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6677 - accuracy: 0.6583\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5965 - accuracy: 0.8333\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6727 - accuracy: 0.6500\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6491 - accuracy: 0.6333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6644 - accuracy: 0.7500\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5577 - accuracy: 0.8250\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5758 - accuracy: 0.8167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5527 - accuracy: 0.9750\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5709 - accuracy: 0.6833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5393 - accuracy: 0.9333\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5051 - accuracy: 0.8167 0s - loss: 0.5054 - accuracy: 0.81\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4949 - accuracy: 0.9333\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4840 - accuracy: 0.8417\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4516 - accuracy: 0.9583\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4381 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4522 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4145 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4436 - accuracy: 0.8583\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4910 - accuracy: 0.9750\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3829 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4086 - accuracy: 0.9750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3386 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4409 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3870 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4087 - accuracy: 0.9333\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4549 - accuracy: 0.8333\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3888 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3073 - accuracy: 0.9750\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4242 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.84 - 0s 34ms/step - loss: 0.4306 - accuracy: 0.8583\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3974 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3404 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4248 - accuracy: 0.9750\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3928 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3846 - accuracy: 0.9583\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3124 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3911 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3903 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86517ca1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  0.0000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.0000\n",
      "Fold 2 Recall :  0.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 31ms/step - loss: 0.8139 - accuracy: 0.2917\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6521 - accuracy: 0.6167\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6423 - accuracy: 0.6583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5599 - accuracy: 0.8250\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6980 - accuracy: 0.5667\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6023 - accuracy: 0.7750\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6152 - accuracy: 0.7667\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6501 - accuracy: 0.7333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5511 - accuracy: 0.7750\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5850 - accuracy: 0.9333\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5070 - accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5353 - accuracy: 0.8833\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5675 - accuracy: 0.8583\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4539 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4726 - accuracy: 0.7667\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3906 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4383 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4999 - accuracy: 0.8167\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3633 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4314 - accuracy: 0.9750\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3872 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3857 - accuracy: 0.8833\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3690 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3425 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3523 - accuracy: 0.8833\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3328 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2703 - accuracy: 1.0000\n",
      "Epoch 28/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2501 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2442 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2936 - accuracy: 0.9750\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2496 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2408 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2718 - accuracy: 0.8417\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2143 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1964 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2160 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1701 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1405 - accuracy: 1.0000 0s - loss: 0.1257 - accuracy: 1.00\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1332 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1721 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1225 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1411 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1102 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1483 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0988 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1522 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1165 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1185 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1210 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1813 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0831 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1412 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1030 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1728 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0979 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0842 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1049 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0856 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1308 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0840 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0871 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1016 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0786 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0949 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 1.00 - 0s 38ms/step - loss: 0.1483 - accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0985 - accuracy: 1.0000 0s - loss: 0.0937 - accuracy: 1.00\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0713 - accuracy: 1.0000\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1143 - accuracy: 1.0000\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1024 - accuracy: 1.0000\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1246 - accuracy: 1.0000\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1678 - accuracy: 1.0000\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1346 - accuracy: 1.0000\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0916 - accuracy: 1.0000\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1389 - accuracy: 1.0000\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0944 - accuracy: 1.0000\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0913 - accuracy: 1.0000\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1461 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f865060d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 35ms/step - loss: 0.6805 - accuracy: 0.5667\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6918 - accuracy: 0.6750\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7327 - accuracy: 0.4500\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6526 - accuracy: 0.6667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6503 - accuracy: 0.5917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5817 - accuracy: 0.7750\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6361 - accuracy: 0.6417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5306 - accuracy: 0.9333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6319 - accuracy: 0.6333\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5023 - accuracy: 0.9750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5067 - accuracy: 0.8583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4862 - accuracy: 0.8833\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5096 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5320 - accuracy: 0.7000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4897 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3765 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3793 - accuracy: 1.0000\n",
      "Epoch 18/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4233 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4059 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4009 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2953 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3171 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3576 - accuracy: 0.8917\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2451 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2777 - accuracy: 0.9583\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2952 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2777 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3476 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2825 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2970 - accuracy: 0.9333\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2146 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2464 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2631 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2777 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2523 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2748 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2288 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2557 - accuracy: 0.8833\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2021 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2528 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1967 - accuracy: 1.0000 0s - loss: 0.1869 - accuracy: 1.00\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2465 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2387 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2021 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2167 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2526 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2118 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3147 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2670 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2950 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f867f04a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 42ms/step - loss: 0.6794 - accuracy: 0.7500\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6995 - accuracy: 0.6667\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7153 - accuracy: 0.4333\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6287 - accuracy: 0.7333\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6846 - accuracy: 0.6167\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6896 - accuracy: 0.6417\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.6037 - accuracy: 0.8917\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.6436 - accuracy: 0.6417\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6324 - accuracy: 0.7917\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4957 - accuracy: 0.8917\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5712 - accuracy: 0.8583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5177 - accuracy: 0.8583\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5451 - accuracy: 0.9583\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4979 - accuracy: 0.7250\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.90 - 0s 41ms/step - loss: 0.5305 - accuracy: 0.8667\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4244 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4554 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4280 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3897 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4066 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3874 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3813 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3978 - accuracy: 0.9750\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3213 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3575 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3977 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3265 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3396 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3034 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3083 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3661 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 1.00 - 0s 38ms/step - loss: 0.3289 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3099 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3193 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3067 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3618 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2903 - accuracy: 1.0000\n",
      "Epoch 38/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2416 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2566 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2698 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2279 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2216 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2358 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2251 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1907 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2631 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2062 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1866 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2626 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1978 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2941 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1916 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2237 - accuracy: 0.8833\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2227 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1928 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2032 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1710 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1594 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2673 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1601 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1951 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1756 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1673 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1386 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1802 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1967 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2031 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8662d1bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "4 rounds average AUC :  1.0000\n",
      "4 rounds average F1 :  0.5333\n",
      "4 rounds average ACC :  0.7500\n",
      "4 rounds average Precision :  0.6000\n",
      "4 rounds average Recall :  0.5000\n",
      "==================== 5 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 37ms/step - loss: 0.7576 - accuracy: 0.2917 0s - loss: 0.7403 - accuracy: 0.27\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6617 - accuracy: 0.7000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7664 - accuracy: 0.3833\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6686 - accuracy: 0.6000\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5950 - accuracy: 0.8667 0s - loss: 0.5878 - accuracy: 0.90\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6347 - accuracy: 0.5917\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5952 - accuracy: 0.8417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5733 - accuracy: 0.8667\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6024 - accuracy: 0.9500\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6725 - accuracy: 0.4083\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5494 - accuracy: 0.7917\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5548 - accuracy: 0.7667\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5503 - accuracy: 0.8833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5060 - accuracy: 0.9583\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6088 - accuracy: 0.8167\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5140 - accuracy: 0.8583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4811 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4785 - accuracy: 0.9583\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4478 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4475 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.84 - 0s 38ms/step - loss: 0.4421 - accuracy: 0.8833\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3350 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3476 - accuracy: 0.9333\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3646 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3564 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3190 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3554 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2163 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2837 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2042 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2564 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2110 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2905 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2137 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2025 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1847 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2078 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1469 - accuracy: 1.0000\n",
      "Epoch 40/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1209 - accuracy: 0.9750\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1032 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1409 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1019 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1136 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1059 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1411 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1062 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1059 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1268 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1067 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1264 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1203 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1878 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0795 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0830 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1237 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0909 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0855 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1124 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1025 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0885 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0934 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1059 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0917 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1054 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1568 - accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0794 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651c121e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "Fold 1 ACC :  1.0000\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 34ms/step - loss: 0.7317 - accuracy: 0.3833\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7407 - accuracy: 0.4333\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7091 - accuracy: 0.5167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6276 - accuracy: 0.7250\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6045 - accuracy: 0.7083\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6565 - accuracy: 0.7250\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6270 - accuracy: 0.6500\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6095 - accuracy: 0.8167\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5987 - accuracy: 0.8833\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5398 - accuracy: 0.8667\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5594 - accuracy: 0.8167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5026 - accuracy: 0.8833\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4469 - accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4999 - accuracy: 0.9333\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5071 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4345 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3973 - accuracy: 0.9583\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4984 - accuracy: 0.7667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4732 - accuracy: 0.8833\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3416 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4795 - accuracy: 0.8167 0s - loss: 0.5033 - accuracy: 0.77\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3601 - accuracy: 0.9750\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3922 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3816 - accuracy: 0.8833\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3698 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4125 - accuracy: 0.9583\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3628 - accuracy: 0.9750\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3452 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3526 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3454 - accuracy: 0.9583\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2965 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3147 - accuracy: 0.9750\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3261 - accuracy: 0.9583\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3284 - accuracy: 0.9333\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3407 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2919 - accuracy: 1.00 - 0s 40ms/step - loss: 0.3104 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3459 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3721 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3836 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3025 - accuracy: 0.9333\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3498 - accuracy: 0.9750\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86517f20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 AUC :  0.5000\n",
      "Fold 2 F1 :  0.5000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 34ms/step - loss: 0.7636 - accuracy: 0.4583\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7292 - accuracy: 0.4583\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6192 - accuracy: 0.6333\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7255 - accuracy: 0.5000\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7063 - accuracy: 0.4667\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6361 - accuracy: 0.7750\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5804 - accuracy: 0.8417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6323 - accuracy: 0.8417\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5711 - accuracy: 0.8417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5618 - accuracy: 0.7917\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5106 - accuracy: 0.9250\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5191 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5431 - accuracy: 0.8917\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4654 - accuracy: 0.8667\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5746 - accuracy: 0.7000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5108 - accuracy: 0.9083\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4915 - accuracy: 0.8833\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4572 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5035 - accuracy: 0.8833\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4489 - accuracy: 1.0000 0s - loss: 0.4459 - accuracy: 1.00\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4970 - accuracy: 0.7917\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4664 - accuracy: 0.9083\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4638 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4022 - accuracy: 0.9750\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3729 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3363 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4601 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3324 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3458 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3624 - accuracy: 0.8833\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4147 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4005 - accuracy: 0.8833\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4231 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3628 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3183 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3677 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3377 - accuracy: 0.9333\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4243 - accuracy: 0.8833\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3685 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3371 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3448 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3441 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3731 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4103 - accuracy: 0.9333\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3861 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8662d7c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  0.5000\n",
      "Fold 3 F1 :  0.6667\n",
      "Fold 3 ACC :  0.7500\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  0.5000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 40ms/step - loss: 0.7287 - accuracy: 0.4583\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6217 - accuracy: 0.7500\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6380 - accuracy: 0.8167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7142 - accuracy: 0.3667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6614 - accuracy: 0.6583\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6259 - accuracy: 0.8000\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6376 - accuracy: 0.7083\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6722 - accuracy: 0.5917 0s - loss: 0.7004 - accuracy: 0.52\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5603 - accuracy: 0.6583\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5598 - accuracy: 0.7500\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5554 - accuracy: 0.8417\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4993 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5460 - accuracy: 0.7000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4949 - accuracy: 0.7750\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5011 - accuracy: 0.9500\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4783 - accuracy: 0.8833\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4916 - accuracy: 0.9167\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4750 - accuracy: 0.9583\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4483 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4746 - accuracy: 0.9750\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4261 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5242 - accuracy: 0.8167\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5017 - accuracy: 0.8167\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4112 - accuracy: 0.9583\n",
      "Epoch 25/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4750 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4114 - accuracy: 0.9333\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3990 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4827 - accuracy: 0.8167\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3889 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4086 - accuracy: 0.9750\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3587 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3445 - accuracy: 0.9500\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4450 - accuracy: 0.9583\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3640 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4218 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3931 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3688 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3804 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3932 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3309 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4005 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4173 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3560 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3444 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3897 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3794 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3355 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3658 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3943 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3569 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3653 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3949 - accuracy: 0.8833\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3623 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3861 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86507e0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.5000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.5000\n",
      "Fold 4 Recall :  0.5000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 37ms/step - loss: 0.8015 - accuracy: 0.2083\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6906 - accuracy: 0.4583\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6713 - accuracy: 0.6583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6600 - accuracy: 0.6167\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7034 - accuracy: 0.5917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6308 - accuracy: 0.5417\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5647 - accuracy: 0.8417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6278 - accuracy: 0.6333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.37 - 0s 36ms/step - loss: 0.6585 - accuracy: 0.4500\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5999 - accuracy: 0.6750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5928 - accuracy: 0.9500 0s - loss: 0.5985 - accuracy: 1.00\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5258 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4933 - accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5279 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4929 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5896 - accuracy: 0.6583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5139 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4289 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4549 - accuracy: 1.0000 0s - loss: 0.4663 - accuracy: 1.00\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4899 - accuracy: 0.8167 0s - loss: 0.4846 - accuracy: 0.81\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4348 - accuracy: 0.9583\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4366 - accuracy: 0.8583\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4507 - accuracy: 0.8833 0s - loss: 0.4547 - accuracy: 0.84\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4327 - accuracy: 0.9750\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4221 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4122 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3959 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4342 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3783 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3302 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4121 - accuracy: 0.8167 0s - loss: 0.4184 - accuracy: 0.77\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3432 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3575 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3414 - accuracy: 0.8833\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3889 - accuracy: 0.8833\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.3674 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3322 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.4038 - accuracy: 0.8833\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3427 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.3848 - accuracy: 1.0000\n",
      "Epoch 41/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2740 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2940 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2944 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3004 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2797 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2562 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3236 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3300 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3325 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3340 - accuracy: 0.9583\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2846 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2702 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3137 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2724 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3436 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2874 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651488b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  0.7500\n",
      "Fold 5 F1 :  0.6667\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  0.5000\n",
      "\n",
      "\n",
      "5 rounds average AUC :  0.7000\n",
      "5 rounds average F1 :  0.6667\n",
      "5 rounds average ACC :  0.7000\n",
      "5 rounds average Precision :  0.8000\n",
      "5 rounds average Recall :  0.6000\n",
      "==================== 6 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 39ms/step - loss: 0.8309 - accuracy: 0.4333\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7804 - accuracy: 0.33 - 0s 37ms/step - loss: 0.7980 - accuracy: 0.3000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7305 - accuracy: 0.4750\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7058 - accuracy: 0.5667 0s - loss: 0.7248 - accuracy: 0.50\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6299 - accuracy: 0.7500\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6445 - accuracy: 0.8167\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5772 - accuracy: 0.7917\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5428 - accuracy: 0.8167\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5836 - accuracy: 0.8417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.93 - 0s 42ms/step - loss: 0.5533 - accuracy: 0.9083\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4859 - accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5198 - accuracy: 0.9583\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5422 - accuracy: 0.7667 0s - loss: 0.5832 - accuracy: 0.69\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4936 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4134 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4581 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4524 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4030 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4163 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3446 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3604 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3474 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3396 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3281 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3464 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3402 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3487 - accuracy: 0.9083\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.3215 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.3475 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3585 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2995 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2849 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2738 - accuracy: 0.9333\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3133 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2839 - accuracy: 0.9750\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.3211 - accuracy: 0.9333\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3038 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.2965 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2990 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3277 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3174 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2617 - accuracy: 0.9750\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3429 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2962 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651b62ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  0.7500\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 32ms/step - loss: 0.7135 - accuracy: 0.5917\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7275 - accuracy: 0.4250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6396 - accuracy: 0.6833\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6196 - accuracy: 0.7667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6935 - accuracy: 0.6250\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5798 - accuracy: 0.9167\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5958 - accuracy: 0.7667\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5310 - accuracy: 0.8667\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5141 - accuracy: 0.9750\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5273 - accuracy: 0.9583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5797 - accuracy: 0.8167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5626 - accuracy: 0.8167\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4892 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4967 - accuracy: 0.9750\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4277 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4645 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3506 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4139 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3790 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3707 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4275 - accuracy: 0.7667\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3316 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 1.00 - 0s 34ms/step - loss: 0.3927 - accuracy: 0.9750\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 1.00 - 0s 42ms/step - loss: 0.2732 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3647 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3304 - accuracy: 1.0000 0s - loss: 0.3461 - accuracy: 1.00\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2532 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.2107 - accuracy: 1.0000 0s - loss: 0.2043 - accuracy: 1.\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.2672 - accuracy: 0.9333\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1904 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2122 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1917 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1742 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2186 - accuracy: 1.0000 0s - loss: 0.2062 - accuracy: 1.00\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2494 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2110 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1878 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1801 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1754 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2434 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1663 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1623 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1830 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1118 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2827 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1545 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2581 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1681 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1782 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1934 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1761 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1563 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2176 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1361 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8662d7c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "Fold 2 ACC :  1.0000\n",
      "Fold 2 Precision :  1.0000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 42ms/step - loss: 0.7361 - accuracy: 0.5083A: 0s - loss: 0.7445 - accuracy: 0.472\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.6938 - accuracy: 0.5250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7273 - accuracy: 0.3917\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6239 - accuracy: 0.7750\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6852 - accuracy: 0.6833\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7115 - accuracy: 0.6833\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5792 - accuracy: 0.9250\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5324 - accuracy: 0.8667\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5541 - accuracy: 0.8000\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6238 - accuracy: 0.6333\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5376 - accuracy: 0.8833\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5948 - accuracy: 0.8417\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4823 - accuracy: 0.8583\n",
      "Epoch 15/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5505 - accuracy: 0.8167\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3961 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4745 - accuracy: 0.8667\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4707 - accuracy: 0.8667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4612 - accuracy: 0.9333\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4512 - accuracy: 0.9750\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4463 - accuracy: 0.8833\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.84 - 0s 42ms/step - loss: 0.4463 - accuracy: 0.8833\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3786 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4531 - accuracy: 0.8833\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4387 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3995 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4435 - accuracy: 0.9333\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4389 - accuracy: 0.8000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3612 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4551 - accuracy: 0.9333\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3855 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3658 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3563 - accuracy: 1.0000 0s - loss: 0.3523 - accuracy: 1.00\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3082 - accuracy: 0.9750\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4738 - accuracy: 0.9333\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 1.00 - 0s 47ms/step - loss: 0.4271 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3846 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 1.00 - 0s 40ms/step - loss: 0.3331 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3689 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3425 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3839 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3411 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4039 - accuracy: 0.9583\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3578 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86518fb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6293 - accuracy: 0.8470 - 3s 37ms/step - loss: 0.6576 - accuracy: 0.7833\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7699 - accuracy: 0.4167\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6274 - accuracy: 0.8667 0s - loss: 0.6117 - accuracy: 0.90\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6644 - accuracy: 0.5667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7149 - accuracy: 0.3667\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.75 - 0s 35ms/step - loss: 0.6027 - accuracy: 0.7750\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6854 - accuracy: 0.4083\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6522 - accuracy: 0.7083\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.84 - 0s 36ms/step - loss: 0.5859 - accuracy: 0.8833\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5446 - accuracy: 0.8417\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5372 - accuracy: 0.7667\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4867 - accuracy: 0.8417\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4854 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4612 - accuracy: 0.9167\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3597 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4308 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3879 - accuracy: 0.8833\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3948 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3739 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3323 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3185 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3286 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3036 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3797 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3518 - accuracy: 0.9750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2240 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2621 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2551 - accuracy: 1.0000 0s - loss: 0.2553 - accuracy: 1.00\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2549 - accuracy: 0.9583\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 1.00 - 0s 40ms/step - loss: 0.2158 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2294 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2458 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2530 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1886 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2230 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1776 - accuracy: 1.0000 0s - loss: 0.1779 - accuracy: 1.00\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2555 - accuracy: 1.0000\n",
      "Epoch 38/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2078 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2562 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2560 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1784 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1733 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2025 - accuracy: 0.9750\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1860 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2208 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f866a444d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "Fold 4 ACC :  0.7500\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  0.5000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 39ms/step - loss: 0.7169 - accuracy: 0.5000\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.7647 - accuracy: 0.5833\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.6823 - accuracy: 0.4333\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7457 - accuracy: 0.3667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6889 - accuracy: 0.5083\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.6649 - accuracy: 0.4833 0s - loss: 0.6624 - accuracy: 0.47\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7001 - accuracy: 0.6000\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6195 - accuracy: 0.8167\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.6008 - accuracy: 0.8250\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4996 - accuracy: 0.9083\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5408 - accuracy: 0.9333\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6014 - accuracy: 0.7750\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5304 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4868 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4851 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4718 - accuracy: 0.9750\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4365 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4402 - accuracy: 0.9333\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4428 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4184 - accuracy: 0.9083\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4435 - accuracy: 0.9333\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4726 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3945 - accuracy: 1.0000 0s - loss: 0.4018 - accuracy: 1.00\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3541 - accuracy: 0.9750\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2592 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3313 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2532 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2728 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2542 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2345 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2644 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2001 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2199 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1985 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 1.00 - ETA: 0s - loss: 0.2103 - accuracy: 1.00 - 0s 52ms/step - loss: 0.2105 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2323 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1356 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1930 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1621 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1741 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.1725 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2057 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1596 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1516 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1739 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1714 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1737 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86648feae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "6 rounds average AUC :  0.9500\n",
      "6 rounds average F1 :  0.8667\n",
      "6 rounds average ACC :  0.9000\n",
      "6 rounds average Precision :  1.0000\n",
      "6 rounds average Recall :  0.8000\n",
      "==================== 7 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 32ms/step - loss: 0.6610 - accuracy: 0.6167\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7163 - accuracy: 0.4583\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7388 - accuracy: 0.4333\n",
      "Epoch 4/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7060 - accuracy: 0.6167\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7053 - accuracy: 0.5500\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.6408 - accuracy: 0.7000\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6127 - accuracy: 0.9083\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5764 - accuracy: 0.6833\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5931 - accuracy: 0.8583 0s - loss: 0.6016 - accuracy: 0.84\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5645 - accuracy: 0.8667\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5302 - accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5428 - accuracy: 0.8167\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5370 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 1.00 - 0s 41ms/step - loss: 0.5000 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5294 - accuracy: 0.8667\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4727 - accuracy: 0.8417\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5211 - accuracy: 0.8417\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.5242 - accuracy: 0.8167\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4634 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4568 - accuracy: 0.9083\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.5595 - accuracy: 0.8167\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4672 - accuracy: 0.8833\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3949 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5090 - accuracy: 0.8833\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4008 - accuracy: 0.9750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4131 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.3771 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4605 - accuracy: 0.8250\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4257 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3675 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.3931 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.3981 - accuracy: 0.9333\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.3497 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.5099 - accuracy: 0.8833\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4607 - accuracy: 0.8833\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3728 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.3940 - accuracy: 0.8833\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.3845 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4006 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.3950 - accuracy: 1.0000 0s - loss: 0.4008 - accuracy: 1.00\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3472 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4599 - accuracy: 0.9583\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3780 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3838 - accuracy: 0.9333\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3882 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3705 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4051 - accuracy: 0.9083\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4059 - accuracy: 0.8583\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3771 - accuracy: 0.8833\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4078 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4195 - accuracy: 0.8833\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4109 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3586 - accuracy: 1.0000 0s - loss: 0.3650 - accuracy: 1.00\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3519 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4175 - accuracy: 0.9750\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.4206 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3445 - accuracy: 0.9500\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4365 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3186 - accuracy: 0.9583\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3662 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3712 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3625 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3502 - accuracy: 0.9750\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3970 - accuracy: 0.9333\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3818 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4732 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3830 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4283 - accuracy: 0.8917\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3887 - accuracy: 0.8583\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f867f0ce730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  0.7500\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 39ms/step - loss: 0.7779 - accuracy: 0.4000\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7210 - accuracy: 0.5917\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7254 - accuracy: 0.3917\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6805 - accuracy: 0.4167\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7725 - accuracy: 0.5167\n",
      "Epoch 6/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7048 - accuracy: 0.4667\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6444 - accuracy: 0.7167\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5699 - accuracy: 0.8417\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5257 - accuracy: 0.9583\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5397 - accuracy: 0.9083\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5680 - accuracy: 0.7750\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4929 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5077 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4991 - accuracy: 0.8333\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4924 - accuracy: 0.9333\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.5073 - accuracy: 0.8833\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3746 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.97 - 0s 35ms/step - loss: 0.4788 - accuracy: 0.9583\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4206 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4062 - accuracy: 0.8833\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4554 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.3238 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 1.00 - 0s 40ms/step - loss: 0.3235 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.3088 - accuracy: 0.9750\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3252 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.3542 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.2292 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3010 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.2864 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2707 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2193 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3028 - accuracy: 1.0000 0s - loss: 0.3176 - accuracy: 1.00\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3103 - accuracy: 0.9750\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2132 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2101 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2828 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.2280 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.2066 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2335 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2124 - accuracy: 1.0000 0s - loss: 0.2262 - accuracy: 1.00\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2020 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2349 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1929 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1994 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2093 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.1828 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.2553 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1715 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2091 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2529 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1973 - accuracy: 0.9750\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.2743 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2050 - accuracy: 0.9750\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1829 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1946 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 1.00 - 0s 42ms/step - loss: 0.2124 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1582 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1552 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2069 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2247 - accuracy: 1.0000 0s - loss: 0.2242 - accuracy: 1.00\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2047 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.2221 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1773 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.2429 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1795 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1822 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2144 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2105 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f866ae10d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  0.7500\n",
      "Fold 2 F1 :  0.6667\n",
      "Fold 2 ACC :  0.7500\n",
      "Fold 2 Precision :  1.0000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.7080 - 4s 38ms/step - loss: 0.6584 - accuracy: 0.6000\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.6977 - accuracy: 0.5917\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.7107 - accuracy: 0.7750\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.6496 - accuracy: 0.7917\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6670 - accuracy: 0.6333\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6654 - accuracy: 0.6583 0s - loss: 0.6680 - accuracy: 0.59\n",
      "Epoch 7/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5717 - accuracy: 0.8167\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5488 - accuracy: 0.9083\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6044 - accuracy: 0.5417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5408 - accuracy: 0.8833\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5854 - accuracy: 0.7917\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4834 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4945 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4712 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5185 - accuracy: 0.9333\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4316 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3898 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3736 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3877 - accuracy: 0.9583\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4505 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3699 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3815 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 1.00 - 0s 37ms/step - loss: 0.3181 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.93 - 0s 38ms/step - loss: 0.3711 - accuracy: 0.9083\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3092 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 1.00 - 0s 37ms/step - loss: 0.2541 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3292 - accuracy: 0.9583\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3024 - accuracy: 0.8833\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2907 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2279 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2980 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2246 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1980 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2009 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1900 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1787 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2587 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1798 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1694 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1676 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.1526 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1316 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1669 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1230 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0866 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.1160 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1320 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0945 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0937 - accuracy: 1.0000 0s - loss: 0.0833 - accuracy: 1.00\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0877 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1047 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1003 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1027 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0673 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0957 - accuracy: 1.0000 0s - loss: 0.0886 - accuracy: 1.00 - ETA: 0s - loss: 0.0914 - accuracy: 1.00\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 1.00 - 0s 42ms/step - loss: 0.0803 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0857 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0677 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0892 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0821 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.0907 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 1.00 - 0s 40ms/step - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1195 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1109 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1155 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1422 - accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0974 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651866950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 31ms/step - loss: 0.7375 - accuracy: 0.3333\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6981 - accuracy: 0.5667\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6752 - accuracy: 0.5583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7373 - accuracy: 0.59 - 0s 31ms/step - loss: 0.7174 - accuracy: 0.5583\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6669 - accuracy: 0.5167\n",
      "Epoch 6/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6630 - accuracy: 0.6500\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6786 - accuracy: 0.6083\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5420 - accuracy: 0.7583\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6110 - accuracy: 0.8417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6639 - accuracy: 0.6333\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5308 - accuracy: 0.8833\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5698 - accuracy: 0.9167\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6210 - accuracy: 0.7417\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5400 - accuracy: 0.7917\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5260 - accuracy: 0.8167\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5243 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4825 - accuracy: 0.8917\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5088 - accuracy: 0.8417\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5234 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5565 - accuracy: 0.8167\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4460 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5257 - accuracy: 0.9333\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4926 - accuracy: 0.9167\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5977 - accuracy: 0.7000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4307 - accuracy: 0.9750 0s - loss: 0.4134 - accuracy: 1.00\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4418 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4156 - accuracy: 0.9750\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4945 - accuracy: 0.8167\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5179 - accuracy: 0.9583\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4596 - accuracy: 1.0000 0s - loss: 0.4620 - accuracy: 1.00\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4554 - accuracy: 0.9750\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4914 - accuracy: 0.8667\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3980 - accuracy: 0.9750\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5029 - accuracy: 0.9750\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4417 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4160 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5139 - accuracy: 0.9333\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5403 - accuracy: 0.9333\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4273 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4330 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3859 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4745 - accuracy: 0.9333\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4749 - accuracy: 0.8417\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4315 - accuracy: 0.9583\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4935 - accuracy: 0.8167\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 1.00 - 0s 43ms/step - loss: 0.3998 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5028 - accuracy: 0.8167\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5222 - accuracy: 0.7667\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.4124 - accuracy: 0.9750\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4956 - accuracy: 0.7750\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4800 - accuracy: 0.8167\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4937 - accuracy: 0.9083\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 1.00 - 0s 38ms/step - loss: 0.4000 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4401 - accuracy: 0.9583\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4743 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4749 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8652601ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "Fold 4 ACC :  0.7500\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  0.5000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 32ms/step - loss: 0.6510 - accuracy: 0.7417\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6664 - accuracy: 0.7250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6812 - accuracy: 0.6667\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6673 - accuracy: 0.6833\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6064 - accuracy: 0.5917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5718 - accuracy: 0.8833\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5677 - accuracy: 0.8167 0s - loss: 0.5707 - accuracy: 0.77\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6139 - accuracy: 0.8167\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5439 - accuracy: 0.9750\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5725 - accuracy: 0.8417\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5197 - accuracy: 0.8917\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5185 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4479 - accuracy: 0.9750\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5284 - accuracy: 0.7917\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4164 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4729 - accuracy: 0.9750\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4327 - accuracy: 0.8833\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4086 - accuracy: 0.8833\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3503 - accuracy: 0.8917\n",
      "Epoch 20/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3504 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3321 - accuracy: 0.9333\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 1.00 - 0s 34ms/step - loss: 0.2840 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2736 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2406 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2808 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2730 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2566 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2759 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2085 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2261 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2403 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1875 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1765 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1847 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1445 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1637 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1524 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1316 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1352 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1299 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1433 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1054 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1670 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1402 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0970 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1264 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1282 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0984 - accuracy: 1.0000 0s - loss: 0.0990 - accuracy: 1.00\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0870 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0998 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0871 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1107 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1107 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1085 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0834 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0745 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0565 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1195 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1095 - accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0464 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1258 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0786 - accuracy: 1.0000 0s - loss: 0.0845 - accuracy: 1.00\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0831 - accuracy: 1.0000\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0838 - accuracy: 1.0000\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0975 - accuracy: 1.0000\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0579 - accuracy: 1.0000 0s - loss: 0.0572 - accuracy: 1.00\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0570 - accuracy: 1.0000\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0622 - accuracy: 1.0000\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1443 - accuracy: 1.0000\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0815 - accuracy: 1.0000\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0601 - accuracy: 1.0000\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0807 - accuracy: 1.0000\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0907 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f865185f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "7 rounds average AUC :  0.9000\n",
      "7 rounds average F1 :  0.8000\n",
      "7 rounds average ACC :  0.8500\n",
      "7 rounds average Precision :  1.0000\n",
      "7 rounds average Recall :  0.7000\n",
      "==================== 8 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 41ms/step - loss: 0.7071 - accuracy: 0.5917\n",
      "Epoch 2/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7390 - accuracy: 0.5000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7264 - accuracy: 0.5000\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7209 - accuracy: 0.4333\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.6722 - accuracy: 0.5250\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6323 - accuracy: 0.7333\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.6431 - accuracy: 0.8167\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6036 - accuracy: 0.8250\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.6497 - accuracy: 0.6833\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.5807 - accuracy: 0.8917\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5942 - accuracy: 0.7083\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5187 - accuracy: 0.8833\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.4735 - accuracy: 0.8583\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.5229 - accuracy: 0.8167\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.4529 - accuracy: 0.8167\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4828 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4860 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4367 - accuracy: 0.9583\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4316 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.3689 - accuracy: 0.9750\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.4367 - accuracy: 0.8833\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4015 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 1.00 - 0s 46ms/step - loss: 0.3634 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3134 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3219 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2940 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.2707 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2218 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2467 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2208 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2256 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1868 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2437 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1515 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1746 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1831 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1484 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1469 - accuracy: 1.0000 0s - loss: 0.1024 - accuracy: 1.00 - ETA: 0s - loss: 0.1211 - accuracy: 1.00\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1524 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.2038 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1225 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1199 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.1492 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0952 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1089 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1501 - accuracy: 1.0000 0s - loss: 0.1528 - accuracy: 1.00\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 1.00 - 0s 52ms/step - loss: 0.0929 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1093 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1405 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1388 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0717 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1446 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0955 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1577 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0971 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1000 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0921 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1777 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1196 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86512e3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.6667\n",
      "Fold 1 ACC :  0.7500\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 36ms/step - loss: 0.6657 - accuracy: 0.7500\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5884 - accuracy: 0.8500\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6126 - accuracy: 0.6417\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6134 - accuracy: 0.8667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6251 - accuracy: 0.7917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5776 - accuracy: 0.8000\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6700 - accuracy: 0.4583\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6796 - accuracy: 0.5917\n",
      "Epoch 9/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5604 - accuracy: 0.6833\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6432 - accuracy: 0.7500\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6205 - accuracy: 0.7667\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6011 - accuracy: 0.7083\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.6098 - accuracy: 0.5667\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5985 - accuracy: 0.7417\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5222 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4751 - accuracy: 0.8833\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5051 - accuracy: 0.8167\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.77 - 0s 41ms/step - loss: 0.5213 - accuracy: 0.8167\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5387 - accuracy: 0.8167\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4498 - accuracy: 0.9083\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6018 - accuracy: 0.6083\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5154 - accuracy: 0.8333\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4704 - accuracy: 0.8667\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5331 - accuracy: 0.9250\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5485 - accuracy: 0.7333\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5132 - accuracy: 0.7500\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86505ea400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  0.2500\n",
      "Fold 2 F1 :  0.4000\n",
      "Fold 2 ACC :  0.2500\n",
      "Fold 2 Precision :  0.3333\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 34ms/step - loss: 0.7849 - accuracy: 0.3917\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7699 - accuracy: 0.3000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7288 - accuracy: 0.3917\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7385 - accuracy: 0.4083\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6780 - accuracy: 0.5750\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6862 - accuracy: 0.6167\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6827 - accuracy: 0.3167\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5667 - accuracy: 0.9333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6059 - accuracy: 0.6167\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6416 - accuracy: 0.7750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6180 - accuracy: 0.8333\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5490 - accuracy: 0.9750\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5231 - accuracy: 0.9500\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6207 - accuracy: 0.6583\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5237 - accuracy: 0.8833 0s - loss: 0.5446 - accuracy: 0.84\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5182 - accuracy: 0.8583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4907 - accuracy: 0.9083\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5433 - accuracy: 1.0000 0s - loss: 0.5476 - accuracy: 1.00\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5685 - accuracy: 0.7417\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4889 - accuracy: 0.9583\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4715 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5815 - accuracy: 0.8000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4980 - accuracy: 0.9333 0s - loss: 0.4965 - accuracy: 0.93\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4538 - accuracy: 0.9083\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4642 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5300 - accuracy: 0.8833\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5254 - accuracy: 0.9583\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.77 - 0s 35ms/step - loss: 0.5265 - accuracy: 0.7917\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5050 - accuracy: 0.9750\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4485 - accuracy: 0.9333\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4347 - accuracy: 0.9500\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4485 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5021 - accuracy: 0.8250\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4413 - accuracy: 0.9750\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4500 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4552 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4596 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4331 - accuracy: 0.9333\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4701 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3892 - accuracy: 0.9333\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4184 - accuracy: 0.8667\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4242 - accuracy: 0.8833\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4320 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4616 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4145 - accuracy: 0.9750\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4561 - accuracy: 0.9333\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4831 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5127 - accuracy: 0.8833\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4695 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4801 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4369 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4501 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8677eb9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 31ms/step - loss: 0.7800 - accuracy: 0.5250\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7561 - accuracy: 0.4500\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6845 - accuracy: 0.6583\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6915 - accuracy: 0.3667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6650 - accuracy: 0.5917\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6349 - accuracy: 0.6167\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5957 - accuracy: 0.6583\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5801 - accuracy: 0.7667\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5603 - accuracy: 0.8667\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5767 - accuracy: 0.8833\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5407 - accuracy: 0.8833\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5302 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.62 - 0s 32ms/step - loss: 0.4985 - accuracy: 0.7000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5366 - accuracy: 0.8000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3808 - accuracy: 0.9583\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 1.00 - 0s 35ms/step - loss: 0.4149 - accuracy: 0.9750\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3915 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4016 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3675 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3810 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3870 - accuracy: 0.9583\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3421 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2886 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3452 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3175 - accuracy: 0.9750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2747 - accuracy: 0.9750\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 1.00 - 0s 35ms/step - loss: 0.3416 - accuracy: 0.9750\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2652 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1973 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2143 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2394 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1954 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2028 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2118 - accuracy: 0.9583\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1682 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2057 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1748 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1824 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1728 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1861 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1920 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1865 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0997 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1278 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1835 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1561 - accuracy: 0.9333\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1296 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1688 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1215 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1376 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1106 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651065620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "Fold 4 ACC :  1.0000\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 35ms/step - loss: 0.6546 - accuracy: 0.6833\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7135 - accuracy: 0.5000\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7017 - accuracy: 0.6167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6500 - accuracy: 0.6833\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6924 - accuracy: 0.4500\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6530 - accuracy: 0.7083\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6532 - accuracy: 0.7250\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7119 - accuracy: 0.3833\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6872 - accuracy: 0.5417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6013 - accuracy: 0.7250\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5911 - accuracy: 0.7167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6034 - accuracy: 0.8000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6374 - accuracy: 0.6417\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5896 - accuracy: 0.8500\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6070 - accuracy: 0.8500\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5734 - accuracy: 0.7667\n",
      "Epoch 17/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5703 - accuracy: 0.7667\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7073 - accuracy: 0.5667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6205 - accuracy: 0.7500\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5074 - accuracy: 0.8250\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5349 - accuracy: 0.8833\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5828 - accuracy: 0.8583\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5571 - accuracy: 0.8417\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5595 - accuracy: 0.7500\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6729 - accuracy: 0.5917\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5606 - accuracy: 0.9083\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5418 - accuracy: 0.8583\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4991 - accuracy: 0.8917\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4510 - accuracy: 0.9333\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5204 - accuracy: 0.9083\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5942 - accuracy: 0.7667\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5640 - accuracy: 0.8667\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5507 - accuracy: 0.9333\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5728 - accuracy: 0.7667\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5287 - accuracy: 0.8167\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.6258 - accuracy: 0.8417\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5938 - accuracy: 0.6333\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6567 - accuracy: 0.6167\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6018 - accuracy: 0.6667\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86676589d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  0.7500\n",
      "Fold 5 F1 :  0.6667\n",
      "Fold 5 ACC :  0.7500\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  0.5000\n",
      "\n",
      "\n",
      "8 rounds average AUC :  0.8000\n",
      "8 rounds average F1 :  0.7467\n",
      "8 rounds average ACC :  0.7500\n",
      "8 rounds average Precision :  0.8667\n",
      "8 rounds average Recall :  0.7000\n",
      "==================== 9 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 42ms/step - loss: 0.7739 - accuracy: 0.3417\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6549 - accuracy: 0.5917\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6373 - accuracy: 0.6667\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7469 - accuracy: 0.5667\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7476 - accuracy: 0.6167\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6438 - accuracy: 0.68 - 0s 46ms/step - loss: 0.6647 - accuracy: 0.6583\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6108 - accuracy: 0.5917\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5549 - accuracy: 0.8417\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6726 - accuracy: 0.6667\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6298 - accuracy: 0.7417\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5905 - accuracy: 0.8000\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5733 - accuracy: 0.9500\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5887 - accuracy: 0.8583\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5286 - accuracy: 0.9500\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5810 - accuracy: 0.7000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5161 - accuracy: 0.9583 0s - loss: 0.4990 - accuracy: 0.97\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5119 - accuracy: 0.8917\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6283 - accuracy: 0.7250\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5672 - accuracy: 0.7667\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5075 - accuracy: 0.8500\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5687 - accuracy: 0.8417\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4761 - accuracy: 0.9083\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5772 - accuracy: 0.7667\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5039 - accuracy: 0.8833\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5930 - accuracy: 0.7750\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5688 - accuracy: 0.9583\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5306 - accuracy: 0.8833\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.90 - 0s 53ms/step - loss: 0.5849 - accuracy: 0.8917\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.5924 - accuracy: 0.7250\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4904 - accuracy: 0.9583\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5630 - accuracy: 0.7583\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5032 - accuracy: 0.9333\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5715 - accuracy: 0.8000 0s - loss: 0.5782 - accuracy: 0.79\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5634 - accuracy: 0.8167\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651beda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  0.7500\n",
      "Fold 1 F1 :  0.5000\n",
      "Fold 1 ACC :  0.5000\n",
      "Fold 1 Precision :  0.5000\n",
      "Fold 1 Recall :  0.5000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 38ms/step - loss: 0.7457 - accuracy: 0.3583\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5953 - accuracy: 0.7750\n",
      "Epoch 3/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6262 - accuracy: 0.6167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5797 - accuracy: 0.7167\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5896 - accuracy: 0.8667\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5984 - accuracy: 0.7500\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5832 - accuracy: 0.8417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6015 - accuracy: 0.6250\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5976 - accuracy: 0.7917\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5962 - accuracy: 0.6833\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5426 - accuracy: 0.8167\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5004 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5044 - accuracy: 0.9333\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5124 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5613 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4401 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4572 - accuracy: 0.9583\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4483 - accuracy: 0.9333\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4704 - accuracy: 0.8833\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.4089 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4594 - accuracy: 0.9583\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4333 - accuracy: 0.8500\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4350 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4249 - accuracy: 0.8417\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5010 - accuracy: 0.8833\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.4616 - accuracy: 0.8417\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4668 - accuracy: 0.8833\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4206 - accuracy: 0.8917\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3780 - accuracy: 1.0000 0s - loss: 0.3637 - accuracy: 1.00\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3903 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4095 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3665 - accuracy: 0.9333\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4343 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4152 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5007 - accuracy: 0.8167\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4232 - accuracy: 0.9750\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.4447 - accuracy: 0.8833\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4108 - accuracy: 0.8833\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4010 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4841 - accuracy: 0.8833\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3680 - accuracy: 0.9583\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.4810 - accuracy: 0.8833 0s - loss: 0.4778 - accuracy: 0.86\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86519d9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  0.7500\n",
      "Fold 2 F1 :  0.5000\n",
      "Fold 2 ACC :  0.5000\n",
      "Fold 2 Precision :  0.5000\n",
      "Fold 2 Recall :  0.5000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 35ms/step - loss: 0.7062 - accuracy: 0.3833\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7089 - accuracy: 0.4333\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.6809 - accuracy: 0.4500\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6831 - accuracy: 0.5917\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6738 - accuracy: 0.5167\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6860 - accuracy: 0.7750\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6285 - accuracy: 0.7333\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6412 - accuracy: 0.6333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5904 - accuracy: 0.7417\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6196 - accuracy: 0.6750\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5947 - accuracy: 0.8833\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5987 - accuracy: 0.7083\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.97 - 0s 34ms/step - loss: 0.5353 - accuracy: 0.8833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5804 - accuracy: 0.7917\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5257 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5303 - accuracy: 0.8167\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5005 - accuracy: 0.8583\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.86 - 0s 37ms/step - loss: 0.5067 - accuracy: 0.8667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4298 - accuracy: 0.9750\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4943 - accuracy: 0.9750\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4784 - accuracy: 0.9750\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4263 - accuracy: 0.8833\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4233 - accuracy: 0.8583\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.3699 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3536 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3822 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3611 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3719 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3381 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2731 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3277 - accuracy: 1.0000\n",
      "Epoch 32/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2806 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2197 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2729 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2848 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2759 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1990 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2494 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1778 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2196 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2278 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1963 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1862 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2116 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2008 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2067 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1676 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2095 - accuracy: 0.9333\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2147 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2032 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.1512 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1402 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1971 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1868 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1601 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1983 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2031 - accuracy: 0.9333\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1866 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1662 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1968 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1312 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8664b08d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 43ms/step - loss: 0.6747 - accuracy: 0.6333\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7821 - accuracy: 0.4500\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.6540 - accuracy: 0.6167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6830 - accuracy: 0.7333\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7334 - accuracy: 0.4083\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6214 - accuracy: 0.7500\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6380 - accuracy: 0.8083\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6229 - accuracy: 0.6167\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6178 - accuracy: 0.8000\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5953 - accuracy: 0.7917\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5756 - accuracy: 0.7750\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5891 - accuracy: 0.7083\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5215 - accuracy: 0.8833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4722 - accuracy: 0.8833\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5476 - accuracy: 0.9083\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4685 - accuracy: 0.9583\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4780 - accuracy: 0.9583\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4357 - accuracy: 0.8667\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4108 - accuracy: 0.9583\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4126 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3923 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4110 - accuracy: 0.8417 0s - loss: 0.4078 - accuracy: 0.81\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3557 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3072 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.3035 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2797 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3185 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2823 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2616 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2853 - accuracy: 0.9583\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2392 - accuracy: 1.0000 0s - loss: 0.2394 - accuracy: 1.00\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2233 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2519 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1731 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2065 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2319 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2483 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2309 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1733 - accuracy: 1.0000\n",
      "Epoch 40/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2616 - accuracy: 0.9333\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2920 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2035 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2472 - accuracy: 0.8833\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2265 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8651c6d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.0000\n",
      "Fold 4 ACC :  0.5000\n",
      "Fold 4 Precision :  0.0000\n",
      "Fold 4 Recall :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 32ms/step - loss: 0.7234 - accuracy: 0.6000\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7334 - accuracy: 0.4833\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6383 - accuracy: 0.7250\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7449 - accuracy: 0.5500\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6617 - accuracy: 0.6583\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6781 - accuracy: 0.5250\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5837 - accuracy: 0.8500\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5602 - accuracy: 0.9333\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5971 - accuracy: 0.8667\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4833 - accuracy: 0.9333\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4848 - accuracy: 0.8250\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5161 - accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4027 - accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4378 - accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4718 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 1.00 - 0s 33ms/step - loss: 0.4322 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4187 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4087 - accuracy: 0.8833\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3232 - accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4089 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2662 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3549 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2460 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3135 - accuracy: 1.0000 0s - loss: 0.2974 - accuracy: 1.00\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2966 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2890 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2409 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2239 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2027 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2183 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2309 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1615 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1565 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1833 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2163 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2072 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2038 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1957 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1844 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1930 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1743 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1509 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1858 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1542 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1597 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1784 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1127 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2106 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1635 - accuracy: 1.0000 0s - loss: 0.1700 - accuracy: 1.00\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1273 - accuracy: 1.0000 0s - loss: 0.1289 - accuracy: 1.00\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1200 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1233 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1859 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1290 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1441 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1445 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1929 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1407 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1910 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1569 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2213 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1845 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86511dd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "Fold 5 ACC :  1.0000\n",
      "Fold 5 Precision :  1.0000\n",
      "Fold 5 Recall :  1.0000\n",
      "\n",
      "\n",
      "9 rounds average AUC :  0.9000\n",
      "9 rounds average F1 :  0.6000\n",
      "9 rounds average ACC :  0.7000\n",
      "9 rounds average Precision :  0.6000\n",
      "9 rounds average Recall :  0.6000\n",
      "==================== 10 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 36ms/step - loss: 0.8180 - accuracy: 0.2500\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7471 - accuracy: 0.2250\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7601 - accuracy: 0.5000\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7621 - accuracy: 0.5750\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6202 - accuracy: 0.7083\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6615 - accuracy: 0.6167\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6499 - accuracy: 0.7417\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6356 - accuracy: 0.6583\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5584 - accuracy: 0.8333\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6439 - accuracy: 0.6250\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5459 - accuracy: 0.8667\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4848 - accuracy: 0.8917\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.5030 - accuracy: 0.8917\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4575 - accuracy: 0.9583\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4075 - accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3990 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4391 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4037 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4708 - accuracy: 0.9500\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.4158 - accuracy: 0.8583\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3813 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3494 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3555 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3293 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4539 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3335 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2959 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2920 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3326 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2678 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2793 - accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2664 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1878 - accuracy: 1.0000 0s - loss: 0.1815 - accuracy: 1.00\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2449 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1932 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2024 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1518 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1266 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1715 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1442 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1572 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1565 - accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1613 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1086 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1177 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1177 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1051 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1426 - accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0936 - accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 1.00 - 0s 42ms/step - loss: 0.1020 - accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0964 - accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0997 - accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1035 - accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0862 - accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0884 - accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1023 - accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1115 - accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0640 - accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0927 - accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0759 - accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1013 - accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1202 - accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0944 - accuracy: 1.0000 0s - loss: 0.0939 - accuracy: 1.00\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1124 - accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1092 - accuracy: 1.0000 0s - loss: 0.1175 - accuracy: 1.00\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0732 - accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0717 - accuracy: 1.0000\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0943 - accuracy: 1.0000 0s - loss: 0.1083 - accuracy: 1.\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1037 - accuracy: 1.0000\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0621 - accuracy: 1.0000\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 76/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0705 - accuracy: 1.0000\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0905 - accuracy: 1.0000\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0916 - accuracy: 1.0000\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1731 - accuracy: 1.0000\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0951 - accuracy: 1.0000\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1024 - accuracy: 1.0000\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 1.00 - 0s 41ms/step - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0812 - accuracy: 1.0000\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0922 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8650788488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "Fold 1 ACC :  1.0000\n",
      "Fold 1 Precision :  1.0000\n",
      "Fold 1 Recall :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 33ms/step - loss: 0.7003 - accuracy: 0.5667\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6953 - accuracy: 0.4833\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7006 - accuracy: 0.5167\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6961 - accuracy: 0.7250\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6202 - accuracy: 0.8000\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6268 - accuracy: 0.5250\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5956 - accuracy: 0.8083\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6010 - accuracy: 0.7667\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5413 - accuracy: 0.8167\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5574 - accuracy: 0.9083\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5214 - accuracy: 0.9083\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5498 - accuracy: 0.8167\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5932 - accuracy: 0.7000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4840 - accuracy: 0.9167\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5298 - accuracy: 0.9083\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5317 - accuracy: 0.7750\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4674 - accuracy: 0.8417\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4571 - accuracy: 0.9333\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4281 - accuracy: 0.9583\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4164 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4692 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4355 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4302 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4365 - accuracy: 0.8167\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3729 - accuracy: 0.9500\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3858 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3814 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3115 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4290 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3749 - accuracy: 0.8833\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3261 - accuracy: 0.9750\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3789 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3720 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2722 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3998 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3896 - accuracy: 0.8833 0s - loss: 0.4138 - accuracy: 0.84\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 1.00 - 0s 41ms/step - loss: 0.3150 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4104 - accuracy: 0.9333\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3279 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3736 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3919 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3039 - accuracy: 0.9167\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.3201 - accuracy: 0.9583\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3868 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86507b2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "Fold 2 ACC :  1.0000\n",
      "Fold 2 Precision :  1.0000\n",
      "Fold 2 Recall :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 3s 35ms/step - loss: 0.6495 - accuracy: 0.8000\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7391 - accuracy: 0.6417\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7034 - accuracy: 0.5417\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6321 - accuracy: 0.7833\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6998 - accuracy: 0.6417\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5503 - accuracy: 0.9583\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5687 - accuracy: 0.8667\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.5030 - accuracy: 1.0000\n",
      "Epoch 9/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5736 - accuracy: 0.7917\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4963 - accuracy: 0.9583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5123 - accuracy: 0.8833\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.5202 - accuracy: 0.8917\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4752 - accuracy: 0.8667\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.5111 - accuracy: 0.9750\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4440 - accuracy: 0.9333\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3836 - accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4576 - accuracy: 0.9333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4225 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3930 - accuracy: 1.0000 0s - loss: 0.3849 - accuracy: 1.00\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3826 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4433 - accuracy: 0.8417\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3829 - accuracy: 0.9333\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3773 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3425 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3498 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4242 - accuracy: 0.9333\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.93 - 0s 40ms/step - loss: 0.3777 - accuracy: 0.9083\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3084 - accuracy: 0.9750\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4676 - accuracy: 0.8833\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3783 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3744 - accuracy: 0.9333\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3177 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3660 - accuracy: 0.8833\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4117 - accuracy: 0.9333\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2928 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2993 - accuracy: 1.0000 0s - loss: 0.3053 - accuracy: 1.00\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3911 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2921 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3744 - accuracy: 0.9583\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3407 - accuracy: 1.0000 0s - loss: 0.3471 - accuracy: 1.00\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 1.00 - 0s 41ms/step - loss: 0.3219 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4246 - accuracy: 0.8167\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3812 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3682 - accuracy: 0.9333\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3929 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4137 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f86516ad2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "Fold 3 ACC :  1.0000\n",
      "Fold 3 Precision :  1.0000\n",
      "Fold 3 Recall :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 37ms/step - loss: 0.7741 - accuracy: 0.4250\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7102 - accuracy: 0.4917\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7134 - accuracy: 0.5417\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.6303 - accuracy: 0.8000 0s - loss: 0.5733 - accuracy: 0.93\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6921 - accuracy: 0.5417\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6729 - accuracy: 0.7083\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7082 - accuracy: 0.4250\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6113 - accuracy: 0.7250\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6775 - accuracy: 0.4750\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6004 - accuracy: 0.9333\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.94 - 0s 36ms/step - loss: 0.5754 - accuracy: 0.8917\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5967 - accuracy: 0.8917\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5717 - accuracy: 0.8000\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5616 - accuracy: 0.9333\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5545 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5443 - accuracy: 0.9333\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5330 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4615 - accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4987 - accuracy: 0.8417\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4906 - accuracy: 0.9333\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4709 - accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4238 - accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4302 - accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3876 - accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3311 - accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3750 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3283 - accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3315 - accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3323 - accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2562 - accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2992 - accuracy: 1.0000\n",
      "Epoch 32/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3213 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3188 - accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2961 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3263 - accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3210 - accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2924 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2626 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2342 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2360 - accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.3438 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2656 - accuracy: 1.0000 0s - loss: 0.2639 - accuracy: 1.00\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2390 - accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2345 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2405 - accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2983 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2991 - accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2685 - accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2818 - accuracy: 0.8833\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2489 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f867efac400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "Fold 4 ACC :  1.0000\n",
      "Fold 4 Precision :  1.0000\n",
      "Fold 4 Recall :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to GRU:  (16, 8, 308) (16, 2)\n",
      "Epoch 1/2000\n",
      "4/4 [==============================] - 4s 37ms/step - loss: 0.6582 - accuracy: 0.6833\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7520 - accuracy: 0.4500\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7461 - accuracy: 0.5917\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7690 - accuracy: 0.4083\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6252 - accuracy: 0.7750\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6377 - accuracy: 0.7083\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6289 - accuracy: 0.6583\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6194 - accuracy: 0.7083\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5589 - accuracy: 0.8500\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6356 - accuracy: 0.7583\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.6510 - accuracy: 0.7750\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5663 - accuracy: 0.9333\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5462 - accuracy: 0.8833\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5359 - accuracy: 0.9583\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5099 - accuracy: 0.8833\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5186 - accuracy: 0.9333\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.5362 - accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 1.00 - 0s 46ms/step - loss: 0.4866 - accuracy: 0.9750\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5375 - accuracy: 0.8833\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5034 - accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4913 - accuracy: 0.9500\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5380 - accuracy: 0.8583\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4603 - accuracy: 0.9583\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4719 - accuracy: 0.8833\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5686 - accuracy: 0.8000\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4337 - accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4911 - accuracy: 0.8833\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4783 - accuracy: 0.9333\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4415 - accuracy: 0.8833\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4728 - accuracy: 0.8833\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5260 - accuracy: 0.8833\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 1.00 - 0s 38ms/step - loss: 0.4184 - accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4428 - accuracy: 0.9583\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4556 - accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5079 - accuracy: 0.9750\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4760 - accuracy: 0.8417\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3780 - accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3918 - accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4666 - accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4967 - accuracy: 0.8667\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4226 - accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4194 - accuracy: 0.9583\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4106 - accuracy: 0.9583 0s - loss: 0.4013 - accuracy: 0.97\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3834 - accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3762 - accuracy: 0.9583\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4404 - accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5012 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8677eb9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUC :  0.7500\r\n",
      "Fold 5 F1 :  0.5000\r\n",
      "Fold 5 ACC :  0.5000\r\n",
      "Fold 5 Precision :  0.5000\r\n",
      "Fold 5 Recall :  0.5000\r\n",
      "\r\n",
      "\r\n",
      "10 rounds average AUC :  0.9500\r\n",
      "10 rounds average F1 :  0.9000\r\n",
      "10 rounds average ACC :  0.9000\r\n",
      "10 rounds average Precision :  0.9000\r\n",
      "10 rounds average Recall :  0.9000\r\n",
      "\r\n",
      "\r\n",
      "#################### Over! ####################\r\n",
      "10 rounds average 5-fold  AUC :  0.8650\r\n",
      "10 rounds average 5-fold  F1 :  0.7280\r\n",
      "10 rounds average 5-fold  ACC :  0.7850\r\n",
      "10 rounds average 5-fold  Precision :  0.8200\r\n",
      "10 rounds average 5-fold  Recall :  0.6900\r\n",
      "\r\n",
      "\r\n",
      "Best seed for 10 rounds:  3\r\n",
      "Best AUC for 10 rounds: 1.0000\r\n",
      "Best F1 for 10 rounds: 0.5333\r\n",
      "True_label: \t\r\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\r\n",
      "Best_pro: \t\r\n",
      "[0.2639439, 0.2699163, 0.79679215, 0.41213748, 0.30117235, 0.34856963, 0.44456503, 0.45401406, 0.15469635, 0.15148813, 0.952778, 0.9601696, 0.15597534, 0.12310423, 0.41584387, 0.43108824, 0.34528485, 0.07315461, 0.7599183, 0.53505695]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 com_dl.py -fn david -clf gru4 -rs 10 -es tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine features (sizes * features * time points):  (20, 308, 8)\n",
      "Label size:  20\n",
      "==================== 1 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "/Users/chenxingjian/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "19 selected features\n",
      "Dimensions to GRU:  (16, 8, 19) (4, 8, 19)\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "94 selected features\n",
      "Dimensions to GRU:  (16, 8, 94) (4, 8, 94)\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  0.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "49 selected features\n",
      "Dimensions to GRU:  (16, 8, 49) (4, 8, 49)\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "77 selected features\n",
      "Dimensions to GRU:  (16, 8, 77) (4, 8, 77)\n",
      "Fold 4 AUC :  0.7500\n",
      "Fold 4 F1 :  0.6667\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "54 selected features\n",
      "Dimensions to GRU:  (16, 8, 54) (4, 8, 54)\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b882c9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "1 rounds average AUC :  0.9500\n",
      "1 rounds average F1 :  0.6667\n",
      "==================== 2 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "79 selected features\n",
      "Dimensions to GRU:  (16, 8, 79) (4, 8, 79)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b898c32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "79 selected features\n",
      "Dimensions to GRU:  (16, 8, 79) (4, 8, 79)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8822b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "49 selected features\n",
      "Dimensions to GRU:  (16, 8, 49) (4, 8, 49)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8a46b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ba3a7ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8a481950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "2 rounds average AUC :  1.0000\n",
      "2 rounds average F1 :  0.9333\n",
      "==================== 3 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "46 selected features\n",
      "Dimensions to GRU:  (16, 8, 46) (4, 8, 46)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8cd7f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 selected features\n",
      "Dimensions to GRU:  (16, 8, 94) (4, 8, 94)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ba3c8bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  0.6667\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "49 selected features\n",
      "Dimensions to GRU:  (16, 8, 49) (4, 8, 49)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8a496620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8e679d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8cd4d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "3 rounds average AUC :  1.0000\n",
      "3 rounds average F1 :  0.8000\n",
      "==================== 4 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "73 selected features\n",
      "Dimensions to GRU:  (16, 8, 73) (4, 8, 73)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b89404ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "91 selected features\n",
      "Dimensions to GRU:  (16, 8, 91) (4, 8, 91)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b86e36730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "20 selected features\n",
      "Dimensions to GRU:  (16, 8, 20) (4, 8, 20)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b87329ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b871826a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "54 selected features\n",
      "Dimensions to GRU:  (16, 8, 54) (4, 8, 54)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b871822f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  0.8000\n",
      "\n",
      "\n",
      "4 rounds average AUC :  1.0000\n",
      "4 rounds average F1 :  0.9600\n",
      "==================== 5 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "86 selected features\n",
      "Dimensions to GRU:  (16, 8, 86) (4, 8, 86)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8a0ef158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "93 selected features\n",
      "Dimensions to GRU:  (16, 8, 93) (4, 8, 93)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8960c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "49 selected features\n",
      "Dimensions to GRU:  (16, 8, 49) (4, 8, 49)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b890af840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  0.5000\n",
      "Fold 3 F1 :  0.6667\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "78 selected features\n",
      "Dimensions to GRU:  (16, 8, 78) (4, 8, 78)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8653ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ba3c94ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "5 rounds average AUC :  0.9000\n",
      "5 rounds average F1 :  0.7333\n",
      "==================== 6 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b87303ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "87 selected features\n",
      "Dimensions to GRU:  (16, 8, 87) (4, 8, 87)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ba5005d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  0.7500\n",
      "Fold 2 F1 :  0.6667\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "70 selected features\n",
      "Dimensions to GRU:  (16, 8, 70) (4, 8, 70)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b87182f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "45 selected features\n",
      "Dimensions to GRU:  (16, 8, 45) (4, 8, 45)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ba3f239d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "********** 5 fold **********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8731a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "6 rounds average AUC :  0.9500\n",
      "6 rounds average F1 :  0.8667\n",
      "==================== 7 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "77 selected features\n",
      "Dimensions to GRU:  (16, 8, 77) (4, 8, 77)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b884ad598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  0.5000\n",
      "Fold 1 F1 :  0.4000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "179 selected features\n",
      "Dimensions to GRU:  (16, 8, 179) (4, 8, 179)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b88408ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "20 selected features\n",
      "Dimensions to GRU:  (16, 8, 20) (4, 8, 20)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b868d0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8dd442f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.6667\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b88408bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "7 rounds average AUC :  0.9000\n",
      "7 rounds average F1 :  0.8133\n",
      "==================== 8 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "19 selected features\n",
      "Dimensions to GRU:  (16, 8, 19) (4, 8, 19)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b890af598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  1.0000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "19 selected features\n",
      "Dimensions to GRU:  (16, 8, 19) (4, 8, 19)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b89022ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "97 selected features\n",
      "Dimensions to GRU:  (16, 8, 97) (4, 8, 97)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b869e9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 selected features\n",
      "Dimensions to GRU:  (16, 8, 77) (4, 8, 77)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8a46bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  0.8000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "96 selected features\n",
      "Dimensions to GRU:  (16, 8, 96) (4, 8, 96)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ba3a7eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "8 rounds average AUC :  1.0000\n",
      "8 rounds average F1 :  0.9600\n",
      "==================== 9 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "84 selected features\n",
      "Dimensions to GRU:  (16, 8, 84) (4, 8, 84)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b878996a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.8000\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "70 selected features\n",
      "Dimensions to GRU:  (16, 8, 70) (4, 8, 70)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b87db9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "49 selected features\n",
      "Dimensions to GRU:  (16, 8, 49) (4, 8, 49)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b87d15378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  0.6667\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b884ad488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8ace2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "9 rounds average AUC :  1.0000\n",
      "9 rounds average F1 :  0.8933\n",
      "==================== 10 repeat ====================\n",
      "********** 1 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "67 selected features\n",
      "Dimensions to GRU:  (16, 8, 67) (4, 8, 67)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b87359bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 1 AUC :  1.0000\n",
      "Fold 1 F1 :  0.6667\n",
      "********** 2 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "71 selected features\n",
      "Dimensions to GRU:  (16, 8, 71) (4, 8, 71)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b890afae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 AUC :  1.0000\n",
      "Fold 2 F1 :  1.0000\n",
      "********** 3 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "70 selected features\n",
      "Dimensions to GRU:  (16, 8, 70) (4, 8, 70)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b873592f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 3 AUC :  1.0000\n",
      "Fold 3 F1 :  1.0000\n",
      "********** 4 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "18 selected features\n",
      "Dimensions to GRU:  (16, 8, 18) (4, 8, 18)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b8a25bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 4 AUC :  1.0000\n",
      "Fold 4 F1 :  1.0000\n",
      "********** 5 fold **********\n",
      "Input dimension:  (16, 308, 8) (16,)\n",
      "Dimensions to FS:  (128, 308) 128 (32, 308) 32\n",
      "16 selected features\n",
      "Dimensions to GRU:  (16, 8, 16) (4, 8, 16)\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b86ec7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5 AUC :  1.0000\n",
      "Fold 5 F1 :  1.0000\n",
      "\n",
      "\n",
      "10 rounds average AUC :  1.0000\n",
      "10 rounds average F1 :  0.9333\n",
      "\n",
      "\n",
      "#################### Over! ####################\n",
      "10 rounds average 5-fold  AUC :  0.9700\n",
      "10 rounds average 5-fold  F1 :  0.8560\n",
      "\n",
      "\n",
      "Best seed for 10 rounds:  1\n",
      "Best AUC for 10 rounds: 1.0000\n",
      "Best F1 for 10 rounds: 0.9333\n",
      "True_label: \t\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "Best_pro: \t\n",
      "[0.2926464, 0.0985174, 0.92647934, 0.6898033, 0.484581, 0.30083442, 0.5328118, 0.5630951, 0.04864438, 0.07326955, 0.91904044, 0.7838696, 0.11849921, 0.1251928, 0.40217915, 0.6782141, 0.005943266, 0.05954244, 0.98432285, 0.9961299]\n"
     ]
    }
   ],
   "source": [
    "!python3 com_fs.py -fn david -clf l1 -rs 10 -es tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondacae0dfadf5d24121af84be8e8dd804ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
